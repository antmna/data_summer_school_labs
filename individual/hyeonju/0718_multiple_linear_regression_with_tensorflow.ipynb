{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "\n",
    "x_data = (boston.data).astype(np.float32)\n",
    "x_concatenate =  np.insert(x_data, 0, np.ones(len(x_data)), 1)\n",
    "x_data = x_concatenate.transpose()\n",
    "\n",
    "y_data = (boston.target).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([1,len(x_data)], -1.0, 1.0))\n",
    "b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[len(x_data),None])\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "hypothesis = tf.matmul(W, X) \n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "W_val = []\n",
    "cost_val = []\n",
    "\n",
    "a = tf.Variable(0.000001)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a) # 라이브러리\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1190.67 [[ 0.66438133  0.65682566 -0.31369787  0.95277447 -0.80259401  0.63811004\n",
      "  -0.49831381  0.54422778 -0.20864819  0.59316427 -0.13629623  0.2941148\n",
      "   0.16386978 -0.90446025]]\n",
      "500000 31.9396 [[ 0.95689225 -0.08972425  0.08927508 -0.0061897  -0.4987607   0.76422191\n",
      "   2.59568834  0.06260153 -0.43453845  0.15626432 -0.00890189  0.25824738\n",
      "   0.02144836 -0.70117569]]\n",
      "1000000 26.5904 [[ 1.12166357 -0.09284396  0.07062396 -0.0056375  -0.25249684  0.82148993\n",
      "   4.11328459  0.0279412  -0.70238215  0.17540705 -0.01020236 -0.0751445\n",
      "   0.01831564 -0.57867581]]\n",
      "1500000 25.1086 [[ 1.24087286 -0.09443837  0.06087724 -0.00529819 -0.04650771  0.84494817\n",
      "   4.88602638  0.01023593 -0.83298004  0.18564546 -0.01083542 -0.25068942\n",
      "   0.01676401 -0.51467174]]\n",
      "2000000 24.668 [[  1.31549263e+00  -9.49271992e-02   5.57104461e-02  -5.43890102e-03\n",
      "    1.33783311e-01   8.44948173e-01   5.27284622e+00   1.37023779e-03\n",
      "   -8.93779933e-01   1.89940885e-01  -1.10978140e-02  -3.39762568e-01\n",
      "    1.59388315e-02  -4.82611954e-01]]\n",
      "2500000 24.4913 [[  1.37509727e+00  -9.48908180e-02   5.21633402e-02  -4.76074172e-03\n",
      "    2.97513217e-01   8.44948173e-01   5.51126480e+00  -4.06590430e-03\n",
      "   -9.23582256e-01   1.93211496e-01  -1.13368686e-02  -3.92598748e-01\n",
      "    1.52846919e-02  -4.63847011e-01]]\n",
      "3000000 24.4269 [[  1.43470192e+00  -9.50557068e-02   5.17685898e-02  -6.69346983e-03\n",
      "    4.46524829e-01   8.44948173e-01   5.55305958e+00  -5.46264043e-03\n",
      "   -9.38394845e-01   1.92857355e-01  -1.12622790e-02  -4.05622035e-01\n",
      "    1.52651975e-02  -4.58531111e-01]]\n",
      "3500000 24.3778 [[ 1.49430656 -0.09479754  0.05159266 -0.00795081  0.59514517  0.84494817\n",
      "   5.55305958 -0.0058244  -0.93967354  0.19211771 -0.01121241 -0.40691116\n",
      "   0.01519938 -0.4577738 ]]\n",
      "4000000 24.3379 [[ 1.55391121 -0.094586    0.05143516 -0.00899696  0.71865261  0.84494817\n",
      "   5.55305958 -0.00614377 -0.94092476  0.19155659 -0.01117369 -0.40830809\n",
      "   0.01514085 -0.45713475]]\n",
      "4500000 24.301 [[ 1.61351585 -0.09438247  0.05128076 -0.0100081   0.8378619   0.84494817\n",
      "   5.55305958 -0.00645582 -0.94217187  0.19102584 -0.01113684 -0.40972343\n",
      "   0.01508358 -0.456516  ]]\n",
      "5000000 24.266 [[ 1.6731205  -0.09417897  0.05112635 -0.01101911  0.95707119  0.84494817\n",
      "   5.55305958 -0.00676785 -0.9434182   0.1904953  -0.0111     -0.41113889\n",
      "   0.01502631 -0.45589724]]\n",
      "5500000 24.2328 [[ 1.73272514 -0.09397542  0.05097193 -0.01203021  1.07628047  0.84494817\n",
      "   5.55305958 -0.00707989 -0.94466513  0.18996458 -0.01106316 -0.41255426\n",
      "   0.01496903 -0.45527852]]\n",
      "6000000 24.2015 [[ 1.79232979 -0.0937719   0.05081755 -0.0130413   1.19548976  0.84494817\n",
      "   5.55305958 -0.00739198 -0.94591266  0.18943387 -0.01102632 -0.41396943\n",
      "   0.01491176 -0.45465967]]\n",
      "6500000 24.172 [[ 1.85193443 -0.09356838  0.05066315 -0.01405229  1.31469905  0.84494817\n",
      "   5.55305958 -0.00770398 -0.94715899  0.18890332 -0.01098949 -0.41538465\n",
      "   0.01485447 -0.45404103]]\n",
      "7000000 24.1525 [[ 1.91153908 -0.09346312  0.0505486  -0.01467522  1.38427508  0.83409613\n",
      "   5.55305958 -0.00790876 -0.94845116  0.18868901 -0.01096946 -0.41689149\n",
      "   0.01481373 -0.45363498]]\n",
      "7500000 24.1347 [[ 1.97114372 -0.0933805   0.05045392 -0.01505988  1.44387972  0.80429381\n",
      "   5.55305958 -0.00805822 -0.94970506  0.18854468 -0.01095122 -0.41826335\n",
      "   0.01477977 -0.45326751]]\n",
      "8000000 24.1209 [[ 2.         -0.09329075  0.05039398 -0.01543066  1.50348437  0.77449149\n",
      "   5.55305958 -0.00814382 -0.95031101  0.18821296 -0.01092001 -0.41892731\n",
      "   0.01476396 -0.45289978]]\n",
      "8500000 24.1108 [[ 2.         -0.09319389  0.05036752 -0.01577695  1.56308901  0.74468917\n",
      "   5.55305958 -0.00817018 -0.95031101  0.18770687 -0.01087693 -0.41892731\n",
      "   0.01476529 -0.4525325 ]]\n",
      "9000000 24.1011 [[ 2.         -0.09309727  0.05033986 -0.01613917  1.62269366  0.71488684\n",
      "   5.55305958 -0.00819589 -0.95031101  0.18719655 -0.01083336 -0.41892731\n",
      "   0.01476652 -0.45216352]]\n",
      "9500000 24.0919 [[ 2.         -0.09299855  0.05031152 -0.01648967  1.6822983   0.68508452\n",
      "   5.55305958 -0.00822507 -0.95031101  0.1867059  -0.01079296 -0.4187727\n",
      "   0.01476399 -0.451814  ]]\n",
      "10000000 24.0831 [[ 2.         -0.0928945   0.05028082 -0.01682087  1.74190295  0.65696174\n",
      "   5.55305958 -0.00826598 -0.95031101  0.18626338 -0.01076048 -0.4182677\n",
      "   0.01475223 -0.45151231]]\n",
      "10500000 24.075 [[ 2.         -0.09278835  0.0502464  -0.01719034  1.80150759  0.63622808\n",
      "   5.55305958 -0.00832242 -0.95031101  0.18582767 -0.01072975 -0.41783258\n",
      "   0.014739   -0.45121679]]\n",
      "11000000 24.0673 [[ 2.         -0.09268217  0.05021196 -0.01755992  1.86111224  0.61549777\n",
      "   5.55305958 -0.00837885 -0.95031101  0.18539192 -0.01069902 -0.41739744\n",
      "   0.01472576 -0.45092136]]\n",
      "11500000 24.0601 [[ 2.         -0.09257602  0.05017754 -0.01792944  1.92071688  0.59476429\n",
      "   5.55305958 -0.0084353  -0.95031101  0.18495628 -0.01066828 -0.4169623\n",
      "   0.01471253 -0.45062587]]\n",
      "12000000 24.0532 [[ 2.         -0.09246981  0.05014309 -0.01829897  1.98032153  0.57402104\n",
      "   5.55305958 -0.00849175 -0.95031101  0.18452036 -0.01063753 -0.41652691\n",
      "   0.01469929 -0.45033041]]\n",
      "12500000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "13000000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "13500000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "14000000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "14500000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "15000000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "15500000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "16000000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "16500000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "17000000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "17500000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "18000000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "18500000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "19000000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "19500000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "20000000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "20500000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "21000000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "21500000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "22000000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "22500000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "23000000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "23500000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "24000000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "24500000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "25000000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "25500000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "26000000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "26500000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "27000000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "27500000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "28000000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "28500000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "29000000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "29500000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n",
      "30000000 24.0511 [[ 2.         -0.09243476  0.05013173 -0.01842093  2.          0.56718326\n",
      "   5.55305958 -0.00851039 -0.95031101  0.18437664 -0.0106274  -0.41638312\n",
      "   0.01469492 -0.45023289]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(30000001):\n",
    "    sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 500000 == 0:\n",
    "        print (step, sess.run(cost, feed_dict={X:x_data, Y:y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max : 29.9601852438\n",
      "min : 0.00303555297792\n"
     ]
    }
   ],
   "source": [
    "x_data = boston.data\n",
    "y_data = boston.target\n",
    "\n",
    "W_val = sess.run(W)[0,1:]\n",
    "b_val = sess.run(W)[0,0]\n",
    "\n",
    "residual_abs = [abs((np.dot(x_data[i],W_val)+b_val)-y_data[i]) for i in range(len(x_data))]\n",
    "\n",
    "print(\"max :\", max(residual_abs))\n",
    "print(\"min :\", min(residual_abs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
